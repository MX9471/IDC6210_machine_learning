{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8129575,"sourceType":"datasetVersion","datasetId":4804958}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"# preprocessing/data manipulation\nimport numpy as np\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split\nfrom sklearn.metrics import make_scorer, accuracy_score, classification_report, f1_score\nimport pandas as pd\n\n\n# classifiers\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:04.460477Z","iopub.execute_input":"2024-04-16T22:32:04.460862Z","iopub.status.idle":"2024-04-16T22:32:07.649924Z","shell.execute_reply.started":"2024-04-16T22:32:04.460833Z","shell.execute_reply":"2024-04-16T22:32:07.648696Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Read CSVs","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/mini-kaggle-project3/test.csv')\n\ntrain_data = pd.read_csv('/kaggle/input/mini-kaggle-project3/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:10.191694Z","iopub.execute_input":"2024-04-16T22:32:10.192412Z","iopub.status.idle":"2024-04-16T22:32:14.346983Z","shell.execute_reply.started":"2024-04-16T22:32:10.192374Z","shell.execute_reply":"2024-04-16T22:32:14.345467Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Splitting and Pre-processing Dataset\n\nHere, we begin pre-processing the dataset. \n\nWe first check the DataFrame for any NA values. Once complete, we continue pre-processing by converting all objects in all categorical columns to numeric values via mapping dictionary. We then split the dataset, stratify the target variable, as well as add a standard scaler. Missing data imputations are conducted as well, using median values so as to mitigate both outlier and skewed data influence. Finally, to reduce dimensionality, we include the PCA function to our training and testing data. ","metadata":{}},{"cell_type":"code","source":"# Check for NAs in entire DataFrame\nprint(train_data.isnull().values.any())\n\n# Check for NAs in the columns\nprint(train_data.isnull().any())\n\n# Check for NAs in the rows\nprint(train_data.isnull().any(axis=1))\n\n# Check for null values in DataFrame\nna_ct = train_data.isnull().values.flatten().sum() \n\n# Count number of False values\nnon_na_ct = train_data.size - na_ct\n\nprint(\"Number of True Values (NAs):\", na_ct)\nprint(\"Number of False values (Non-NAs):\", non_na_ct)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:15.086112Z","iopub.execute_input":"2024-04-16T22:32:15.086515Z","iopub.status.idle":"2024-04-16T22:32:15.262215Z","shell.execute_reply.started":"2024-04-16T22:32:15.086485Z","shell.execute_reply":"2024-04-16T22:32:15.260189Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"False\nElevation                             False\nAspect                                False\nSlope                                 False\nHorizontal_Distance_To_Hydrology      False\nVertical_Distance_To_Hydrology        False\nHorizontal_Distance_To_Roadways       False\nHillshade_9am                         False\nHillshade_Noon                        False\nHillshade_3pm                         False\nHorizontal_Distance_To_Fire_Points    False\nWilderness_Area1                      False\nWilderness_Area2                      False\nWilderness_Area3                      False\nWilderness_Area4                      False\nSoil_Type1                            False\nSoil_Type2                            False\nSoil_Type3                            False\nSoil_Type4                            False\nSoil_Type5                            False\nSoil_Type6                            False\nSoil_Type7                            False\nSoil_Type8                            False\nSoil_Type9                            False\nSoil_Type10                           False\nSoil_Type11                           False\nSoil_Type12                           False\nSoil_Type13                           False\nSoil_Type14                           False\nSoil_Type15                           False\nSoil_Type16                           False\nSoil_Type17                           False\nSoil_Type18                           False\nSoil_Type19                           False\nSoil_Type20                           False\nSoil_Type21                           False\nSoil_Type22                           False\nSoil_Type23                           False\nSoil_Type24                           False\nSoil_Type25                           False\nSoil_Type26                           False\nSoil_Type27                           False\nSoil_Type28                           False\nSoil_Type29                           False\nSoil_Type30                           False\nSoil_Type31                           False\nSoil_Type32                           False\nSoil_Type33                           False\nSoil_Type34                           False\nSoil_Type35                           False\nSoil_Type36                           False\nSoil_Type37                           False\nSoil_Type38                           False\nSoil_Type39                           False\nSoil_Type40                           False\nlabel                                 False\nid                                    False\ndtype: bool\n0         False\n1         False\n2         False\n3         False\n4         False\n          ...  \n464804    False\n464805    False\n464806    False\n464807    False\n464808    False\nLength: 464809, dtype: bool\nNumber of True Values (NAs): 0\nNumber of False values (Non-NAs): 26029304\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a mapping dictionary for all categorical columns\nmapping_dict = {}\n\nfor col in train_data.columns: \n    if train_data[col].dtype == 'object': \n        mapping = {label: idx for idx, label in enumerate(np.unique(train_data[col]))}\n        mapping_dict[col] = mapping\n\nfor col, mapping in mapping_dict.items():\n    train_data[col] = train_data[col].map(mapping)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:18.276328Z","iopub.execute_input":"2024-04-16T22:32:18.276759Z","iopub.status.idle":"2024-04-16T22:32:18.291379Z","shell.execute_reply.started":"2024-04-16T22:32:18.276727Z","shell.execute_reply":"2024-04-16T22:32:18.289642Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Training Data \nX = train_data.drop(columns =['label'], axis = 1)\ny = train_data['label']\n\n# Stratified train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:20.200536Z","iopub.execute_input":"2024-04-16T22:32:20.201019Z","iopub.status.idle":"2024-04-16T22:32:20.809621Z","shell.execute_reply.started":"2024-04-16T22:32:20.200986Z","shell.execute_reply":"2024-04-16T22:32:20.808206Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Adding standard scaling to X_train and X_test\nsc = StandardScaler()\n\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:22.103240Z","iopub.execute_input":"2024-04-16T22:32:22.103642Z","iopub.status.idle":"2024-04-16T22:32:22.535825Z","shell.execute_reply.started":"2024-04-16T22:32:22.103615Z","shell.execute_reply":"2024-04-16T22:32:22.534603Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Handling Missing Data\nimputer = SimpleImputer(strategy='median')\nX_train_imputed = imputer.fit_transform(X_train_scaled)\nX_test_imputed = imputer.transform(X_test_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:23.789789Z","iopub.execute_input":"2024-04-16T22:32:23.790238Z","iopub.status.idle":"2024-04-16T22:32:26.805053Z","shell.execute_reply.started":"2024-04-16T22:32:23.790204Z","shell.execute_reply":"2024-04-16T22:32:26.803815Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Further pre-processing data by applying PCA\npca = PCA(n_components=10)\nX_train_pca = pca.fit_transform(X_train_imputed)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:27.611424Z","iopub.execute_input":"2024-04-16T22:32:27.611882Z","iopub.status.idle":"2024-04-16T22:32:30.463551Z","shell.execute_reply.started":"2024-04-16T22:32:27.611849Z","shell.execute_reply":"2024-04-16T22:32:30.462274Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Employing Classification Methods on Training Dataset\n\nAfter pre-processing is complete, we then begin running the training dataset through each classification method. \n\nWe first introduce each classifier method and then conduct cross-validation to check the robustness of each model. Additionally, cross-validation helps in fine-tuning the hyperparameters used in the evaluation of the dataset. For the purpose of this project, 5 folds will be used, save for SVM. \n\nThe F1 scores of each will be shown as an output to compare, with the mean F1 score of the 5 splits being used as final metric to choose the best model. ","metadata":{}},{"cell_type":"markdown","source":"## Perceptron\n\nPerceptron may be able to introduce the concept of classifiers, but its simple nature may not be able to handle the complexity of larger datasets, especially with imbalanced classes. Because of this, the resulting mean F1 score is the lowest out of all the classifiers used. ","metadata":{}},{"cell_type":"code","source":"# Introduce model\npercep_clf = Perceptron()\n\n# Cross-validation \ncv_percep = cross_val_score(percep_clf, X_train_pca, y_train, cv=5, scoring='f1_weighted')\n\n# Print F1 scores\nprint(\"Cross-validation F1 scores:\", cv_percep)\nprint(\"Mean F1 score:\", cv_percep.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regression\n\nSimilarly to Perceptron, the Logistic Regression model suffers when datasets become too large or too complex, leading to suboptimal scores. While logistic regression *does* have more robustness in comparison to perceptron, the resulting F1 score does not show much improvement overall. ","metadata":{}},{"cell_type":"code","source":"# Introduce model\nlr_clf = LogisticRegression(max_iter=2000, penalty='l2', C=1.0)\n\n# Cross-validation \ncv_lr = cross_val_score(lr_clf, X_train_pca, y_train, cv=5, scoring='f1_weighted')\n\n# Print F1 scores\nprint(\"Cross-validation F1 scores:\", cv_lr)\nprint(\"Mean F1 score:\", cv_lr.mean())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SVM \n\nWhen attempting to utilize SVM, the computation time was simply too long to produce any tangible output. Constant adjustments to n_components, parameter range, or even the number of iterations did not seem to make much of a difference. In this case, SVM could possibly be considered *too* complex to take on the dataset. \n\nOn a personal note, I felt it necessary to add the code to at least record the attempt and remark on the output (or lack thereof). If improvements are to be considered, perhaps adjustments to the class imbalances could be made - specifically in terms of up or downsampling. ","metadata":{}},{"cell_type":"code","source":"# Create separate PCA in order to reduce number of features to 2\npca = PCA(n_components=2)\nX_train_pca = pca.fit_transform(X_train_imputed)\n\n# Create a pipeline for SVM and Standard Scaling\npipe_svc = make_pipeline(\n    StandardScaler(),\n    SVC(random_state=1),\n)\n\n# Define parameter distributions for random search\nparam_range = [0.01, 1.0, 100.0]\n\nparam_grid = [{'svc__C': param_range,\n              'svc__kernel': ['linear']},\n             {'svc__C': param_range,\n             'svc__gamma': param_range,\n             'svc__kernel': ['rbf']}]\n\n# Creating Randomized Search, setting estimators, parameters, and maximum CPU usage \nrs = RandomizedSearchCV(estimator=pipe_svc, param_distributions=param_grid, scoring='f1_weighted', refit=True, n_iter=5, cv=5, random_state=1, n_jobs=-1)\nrs.fit(X_train_pca, y_train)\n\n# Get the best parameters and best F1 score\nbest_params = rs.best_params_\nbest_score = rs.best_score_\n\n# Print F1 scores\nprint(\"Best Parameters:\", best_params)\nprint(\"Best F1 Score:\", best_score)","metadata":{"execution":{"iopub.status.busy":"2024-04-16T20:40:05.123128Z","iopub.execute_input":"2024-04-16T20:40:05.123624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Decision Tree\n\nDecision Tree was able to fare better in terms of F1 score. This may be due to its robust nature and ability to model complex, non-linear relationships from large datasets, moreso than logistic regression. Additionally, it naturally performs feature selection by choosing the most relevant and informative features at each split. Unfortunately, while this *does* showcase a considerable improvement from logistic regression, it neither surpasses the required F1 score percentage, nor is it the highest F1 score overall. ","metadata":{}},{"cell_type":"code","source":"# Introduce model\ndt_clf = DecisionTreeClassifier()\n\n# Cross-validation\ncv_dt = cross_val_score(dt_clf, X_train_pca, y_train, cv=5, scoring='f1_weighted')\n\n# Print F1 scores\nprint(\"Cross-validation F1 scores:\", cv_dt)\nprint(\"Mean F1 score:\", cv_dt.mean())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:32:37.678417Z","iopub.execute_input":"2024-04-16T22:32:37.678845Z","iopub.status.idle":"2024-04-16T22:33:32.089985Z","shell.execute_reply.started":"2024-04-16T22:32:37.678813Z","shell.execute_reply":"2024-04-16T22:33:32.088650Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Cross-validation F1 scores: [0.85730482 0.85545796 0.8553183  0.85894307 0.8565576 ]\nMean F1 score: 0.8567163510468265\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## K-Nearest Neighbors\n\nBeing a nonparametric classifier, KNN does not make any assumptions about the underlying data distribution. With this advantage, KNN is able to outperform logistic regression and perceptron. Exchanging computational expense for robustness, KNN is able to handle large and complex datasets, being able to achieve a score both higher than decision tree, and enough to surpass the required F1 score percentage. However, it does not have the highest score overall. ","metadata":{}},{"cell_type":"code","source":"# Introduce model\nknn_clf = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n\n# Cross-validation\ncv_knn = cross_val_score(knn_clf, X_train_pca, y_train, cv=5, scoring='f1_weighted')\n\n# Print F1 scores\nprint(\"Cross-validation F1 scores:\", cv_knn)\nprint(\"Mean F1 score:\", cv_knn.mean())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:34:18.658181Z","iopub.execute_input":"2024-04-16T22:34:18.658703Z","iopub.status.idle":"2024-04-16T22:35:01.985606Z","shell.execute_reply.started":"2024-04-16T22:34:18.658673Z","shell.execute_reply":"2024-04-16T22:35:01.984657Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Cross-validation F1 scores: [0.88836871 0.88876536 0.88836229 0.88969826 0.88812142]\nMean F1 score: 0.8886632090693791\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random Forest\n\n**This classification method was chosen**, as it had the highest overall F1 score among the tested classifier methods. While one decision tree alone may not be enough to produce an adequate F1 score, having multiple decision trees would allow for a significant improvement in predictions. With multiple decision trees producing an aggregate prediction, less variance is generated, and increases the overall F1 score. \n\nFor these reasons, Random Forest shall be selected as the chosen classifier method.","metadata":{}},{"cell_type":"code","source":"# This classifier was chosen due to having the highest F1 score overall\n\n# Introduce model, setting additional parameters for n number of trees and maximum CPU usage \nrf_clf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n\n# Cross-validation\ncv_rf = cross_val_score(rf_clf, X_train_pca, y_train, cv=5, scoring='f1_weighted')\n\n# Print F1 scores\nprint(\"Cross-validation F1 scores:\", cv_rf)\nprint(\"Mean F1 score:\", cv_rf.mean())","metadata":{"execution":{"iopub.status.busy":"2024-04-16T22:35:01.987583Z","iopub.execute_input":"2024-04-16T22:35:01.988330Z","iopub.status.idle":"2024-04-16T22:38:55.361518Z","shell.execute_reply.started":"2024-04-16T22:35:01.988293Z","shell.execute_reply":"2024-04-16T22:38:55.359895Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Cross-validation F1 scores: [0.91565308 0.91559906 0.91386446 0.91460716 0.91414672]\nMean F1 score: 0.9147740973880507\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Preparing Classifer Method for Test Dataset\n\nHere, we create the code to pre-process the training and testing dataset to be evaluated by the Random Forest algorithm. The code remains mostly the same as earlier, with the biggest differences being the mapping of the categorical data in the test set, as well as encoding the results of the label to a new column. ","metadata":{}},{"cell_type":"code","source":"# Create a mapping dictionary for all categorical columns\nmapping_dict = {}\n\n# Creating mapping dictionary for training data\nfor col in train_data.columns: \n    if train_data[col].dtype == 'object': \n        mapping = {label: idx for idx, label in enumerate(np.unique(train_data[col]))}\n        mapping_dict[col] = mapping\n\nfor col, mapping in mapping_dict.items():\n    train_data[col] = train_data[col].map(mapping)\n\n# Creating mapping dictionary for testing data    \nfor col in test_data.columns: \n    if test_data[col].dtype == 'object': \n        mapping = {label: idx for idx, label in enumerate(np.unique(test_data[col]))}\n        mapping_dict[col] = mapping\n\nfor col, mapping in mapping_dict.items():\n    test_data[col] = test_data[col].map(mapping)\n    \n# Training Data \nX_train = train_data.drop(columns =['label'], axis = 1)\ny_train = train_data['label']\n\n# Test Data\nX_test = test_data\n\n# Adding standard scaling to X_train and X_test\nsc = StandardScaler()\n\nX_train_scaled = sc.fit_transform(X_train)\nX_test_scaled = sc.transform(X_test)\n\n# Handling Missing Data\nimputer = SimpleImputer(strategy='median')\nX_train_imputed = imputer.fit_transform(X_train_scaled)\nX_test_imputed = imputer.transform(X_test_scaled)\n\n# Further Pre-Processing Data w/ PCA \npca = PCA(n_components=10)\nX_train_pca = pca.fit_transform(X_train_imputed)\nX_test_pca = pca.fit_transform(X_test_imputed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating Testing Dataset and Generating CSV File\n\nOnce the data from the training and testing dataset have been pre-processed, the testing dataset is then evaluated with our chosen classifer method, of which the results will be converted to a csv file. ","metadata":{}},{"cell_type":"code","source":"rf2 = RandomForestClassifier()\n\nrf2.fit(X_train_pca, y_train)\n\nrf2_pred = rf2.predict(X_test_pca)\nresult = pd.DataFrame({'id': test_data.id, 'label': rf2_pred})\nresult.to_csv('submission.csv', index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Final Visualization\n\nOnce the csv file has been generated, a final check and visualization of the DataFrame is conducted before submission.  ","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/working/submission.csv')\nprint(submission)\n\nvalue_counts = submission['label'].value_counts()\nprint(value_counts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}