{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7942402,"sourceType":"datasetVersion","datasetId":4669700}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Setting up methods and packages\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd\nfrom distutils.version import LooseVersion\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import tree\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:17:55.313425Z","iopub.execute_input":"2024-03-26T11:17:55.313923Z","iopub.status.idle":"2024-03-26T11:17:58.093764Z","shell.execute_reply.started":"2024-03-26T11:17:55.313881Z","shell.execute_reply":"2024-03-26T11:17:58.092486Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Setting up dataframe from directory\ndf = pd.read_csv('/kaggle/input/mini-kaggle2-dataset/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:17:58.745799Z","iopub.execute_input":"2024-03-26T11:17:58.747332Z","iopub.status.idle":"2024-03-26T11:17:58.772175Z","shell.execute_reply.started":"2024-03-26T11:17:58.747277Z","shell.execute_reply":"2024-03-26T11:17:58.770917Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Dropping non-informative and target columns from X and assigning target column to Y\nX = df.drop(columns=[\"id\", \"label\"])\ny = df['label']\n\n# Splitting the training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:18:00.236497Z","iopub.execute_input":"2024-03-26T11:18:00.237364Z","iopub.status.idle":"2024-03-26T11:18:00.255210Z","shell.execute_reply.started":"2024-03-26T11:18:00.237319Z","shell.execute_reply":"2024-03-26T11:18:00.254225Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Gathering brief summary of dataset\ndf.head","metadata":{"execution":{"iopub.status.busy":"2024-03-26T09:58:39.899321Z","iopub.execute_input":"2024-03-26T09:58:39.899702Z","iopub.status.idle":"2024-03-26T09:58:39.929069Z","shell.execute_reply.started":"2024-03-26T09:58:39.899673Z","shell.execute_reply":"2024-03-26T09:58:39.927820Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of            id label  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    90524101     M        17.99         20.66          117.80      991.7   \n1    84358402     M        20.29         14.34          135.10     1297.0   \n2       89346     B         9.00         14.40           56.36      246.3   \n3      902975     B        12.21         14.09           78.78      462.0   \n4      904969     B        12.34         14.95           78.29      469.1   \n..        ...   ...          ...           ...             ...        ...   \n450    866674     M        19.79         25.12          130.40     1192.0   \n451    869254     B        10.75         14.97           68.26      355.3   \n452    859717     M        17.20         24.52          114.20      929.4   \n453  88249602     B        14.03         21.25           89.79      603.4   \n454    854941     B        13.03         18.42           82.61      523.8   \n\n     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0            0.10360           0.13040        0.120100             0.088240   \n1            0.10030           0.13280        0.198000             0.104300   \n2            0.07005           0.03116        0.003681             0.003472   \n3            0.08108           0.07823        0.068390             0.025340   \n4            0.08682           0.04571        0.021090             0.020540   \n..               ...               ...             ...                  ...   \n450          0.10150           0.15890        0.254500             0.114900   \n451          0.07793           0.05139        0.022510             0.007875   \n452          0.10710           0.18300        0.169200             0.079440   \n453          0.09070           0.06945        0.014620             0.018960   \n454          0.08983           0.03766        0.025620             0.029230   \n\n     ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0    ...        21.080          25.41           138.10      1349.0   \n1    ...        22.540          16.67           152.20      1575.0   \n2    ...         9.699          20.07            60.90       285.5   \n3    ...        13.130          19.29            87.65       529.9   \n4    ...        13.180          16.85            84.11       533.1   \n..   ...           ...            ...              ...         ...   \n450  ...        22.630          33.58           148.70      1589.0   \n451  ...        11.950          20.72            77.79       441.2   \n452  ...        23.320          33.82           151.60      1681.0   \n453  ...        15.330          30.28            98.27       715.5   \n454  ...        13.300          22.81            84.46       545.9   \n\n     smoothness_worst  compactness_worst  concavity_worst  \\\n0             0.14820            0.37350          0.33010   \n1             0.13740            0.20500          0.40000   \n2             0.09861            0.05232          0.01472   \n3             0.10260            0.24310          0.30760   \n4             0.10480            0.06744          0.04921   \n..                ...                ...              ...   \n450           0.12750            0.38610          0.56730   \n451           0.10760            0.12230          0.09755   \n452           0.15850            0.73940          0.65660   \n453           0.12870            0.15130          0.06231   \n454           0.09701            0.04619          0.04833   \n\n     concave points_worst  symmetry_worst  fractal_dimension_worst  \n0                 0.19740          0.3060                  0.08503  \n1                 0.16250          0.2364                  0.07678  \n2                 0.01389          0.2991                  0.07804  \n3                 0.09140          0.2677                  0.08824  \n4                 0.04793          0.2298                  0.05974  \n..                    ...             ...                      ...  \n450               0.17320          0.3305                  0.08465  \n451               0.03413          0.2300                  0.06769  \n452               0.18990          0.3313                  0.13390  \n453               0.07963          0.2226                  0.07617  \n454               0.05013          0.1987                  0.06169  \n\n[455 rows x 32 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"# Setting up the perceptron model\nppn = Perceptron(eta0=0.1, random_state=1)\n\n# Fitting the perceptron model via scikit-learn\nppn.fit(X_train, y_train)\n\n# Making predictions\ny_pred = ppn.predict(X_test)\n\n# Setting up accuracy score output\nprint('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n\n# While still producing a somewhat feasible accuracy score, the perceptron \n# model suffers from its simplistic nature. Sensitivity to feature scaling, \n# inability to approximate non-linear functions, and convergence issues\n# limit the model to create an adequate accuracy score. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T09:58:42.618960Z","iopub.execute_input":"2024-03-26T09:58:42.619621Z","iopub.status.idle":"2024-03-26T09:58:42.640782Z","shell.execute_reply.started":"2024-03-26T09:58:42.619588Z","shell.execute_reply":"2024-03-26T09:58:42.639316Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Accuracy: 0.679\n","output_type":"stream"}]},{"cell_type":"code","source":"#Train logistic regression model. Set Max iterations to 3000 to prevent convergence warning\nlrmodel = LogisticRegression(max_iter=3000)\nlrmodel.fit(X_train, y_train)\n\n# Making predictions of the model\nlr_pred = lrmodel.predict(X_test)\n\n# Setting up accuracy score\nlraccuracy = accuracy_score(y_test, lr_pred)\nprint(\"Logistic Regression Accuracy \", {lraccuracy})\n\n# Load the test data from test CSV file\ntest_data = pd.read_csv('/kaggle/input/mini-kaggle2-dataset/test.csv')\n\n# Drop the same columns from the test data\ntest_data = test_data.drop('id', axis=1)\n\n# Make predictions on the test data\npredictions = lrmodel.predict(test_data)\n\n# Create a new DataFrame from predictions conducted\nnew_predictions_df = pd.DataFrame({'Predictions': predictions})\n\n# Reload the test.csv DataFrame to add back id column\ntest_data2 = pd.read_csv('/kaggle/input/mini-kaggle2-dataset/test.csv')\n\n# Add the id column from test_data2 to the new DataFrame\nnew_predictions_df.insert(0, 'id', test_data2['id'])\n\n# Save the predictions to a new CSV file\nnew_predictions_df.to_csv('prediction.csv', index=False)\n\n# Print new DataFrame\nprint(new_predictions_df)\n\n# Logistic Regression makes for a strong contender in this evaluation, \n# as it able to work well with large datasets, can be regularized to avoid \n# overfitting, and is simple to interpret. However, in this case, Logistic \n# Regression is only slightly edged out by Random Forest in terms of \n# accuracy score when performing the final evaluation. This is further \n# explained in Random Forest's section. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T10:22:57.045897Z","iopub.execute_input":"2024-03-26T10:22:57.046931Z","iopub.status.idle":"2024-03-26T10:22:57.611956Z","shell.execute_reply.started":"2024-03-26T10:22:57.046873Z","shell.execute_reply":"2024-03-26T10:22:57.610823Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy  {0.9635036496350365}\n           id Predictions\n0      906564           M\n1       85715           B\n2      891670           B\n3      874217           M\n4      905680           M\n..        ...         ...\n109     87164           M\n110  84348301           M\n111    859471           B\n112    911150           B\n113  90944601           B\n\n[114 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting up the SVM model\n# Additionally setting regularization parameters gamma and C for decision boundaries\nsvm = SVC(kernel='rbf', random_state=1, gamma=100.0, C=1.0)\n\n# Fitting the SVM model via scikit-learn\nsvm.fit(X_train, y_train)\n\n# Making predictions\nsvm_pred = svm.predict(X_test)\n\n# Setting up accuracy score\nsvmaccuracy = accuracy_score(y_test, svm_pred)\nprint(\"SVM Accuracy \", {svmaccuracy})\n\n# SVM's accuracy score is similar to Perceptron's, which was surprising. However, \n# some reasons for this could be due to feature scaling. If the scaling was more \n# optimally tuned, perhaps the accuracy could improve. Additionally, overfitting \n# may occur, especially with smaller datasets with less observations. These reasons\n# could explain the lower accuracy score when compared with the other models. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T08:51:17.124159Z","iopub.execute_input":"2024-03-26T08:51:17.124533Z","iopub.status.idle":"2024-03-26T08:51:17.152116Z","shell.execute_reply.started":"2024-03-26T08:51:17.124504Z","shell.execute_reply":"2024-03-26T08:51:17.150884Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"SVM Accuracy  {0.6496350364963503}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting up the Decision Tree model\n# Additionally setting parameters to check for gini impurities and setting max depth of decision tree\ntree_model = DecisionTreeClassifier(criterion='gini', \n                                    max_depth=4, \n                                    random_state=1)\n\n# Fitting the Decision Tree model via scikit-learn\ntree_model.fit(X_train, y_train)\n\n# Making predictions\ntree_pred = tree_model.predict(X_test)\n\n# Setting up accuracy score \ntreeaccuracy = accuracy_score(y_test, tree_pred)\nprint(\"Tree Accuracy \", {treeaccuracy})\n\n# While the Decision Tree's accuracy score is a markedly larger improvement over SVM's, \n# it is still not quite enough to be considered the best model for the final evaluation. \n# One reason for its lower score could be due to it being impaired by overfitting. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T08:51:20.328736Z","iopub.execute_input":"2024-03-26T08:51:20.329148Z","iopub.status.idle":"2024-03-26T08:51:20.349916Z","shell.execute_reply.started":"2024-03-26T08:51:20.329115Z","shell.execute_reply":"2024-03-26T08:51:20.348591Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Tree Accuracy  {0.9343065693430657}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Setting up the KNN model\n# Additionally setting parameters of Minkowski distance and specifying number of neighbors to consider\nknn = KNeighborsClassifier(n_neighbors=5, \n                           p=2, \n                           metric='minkowski')\n\n# Fitting the KNN model via scikit-learn\nknn.fit(X_train, y_train)\n\n# Making predictions\nknn_pred = knn.predict(X_test)\n\n# Setting up accuracy score\nknnaccuracy = accuracy_score(y_test, knn_pred)\nprint(\"KNN Accuracy \", {knnaccuracy})\n\n# Like the Decision Tree model, KNN also produces serviceable results, albeit lower than desired. \n# The reasons for this remain the same as before - overfitting and a lack of feature scability. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T08:51:24.247677Z","iopub.execute_input":"2024-03-26T08:51:24.248354Z","iopub.status.idle":"2024-03-26T08:51:24.338351Z","shell.execute_reply.started":"2024-03-26T08:51:24.248320Z","shell.execute_reply":"2024-03-26T08:51:24.337149Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"KNN Accuracy  {0.9124087591240876}\n","output_type":"stream"}]},{"cell_type":"code","source":"#### This model was selected as the final choice for predicting the test dataset ####\n\n# Setting up the Random Forest model\n# Additionally setting parameters for number of estimators and jobs\nforest = RandomForestClassifier(n_estimators=25, \n                                random_state=1,\n                                n_jobs=2)\n\n# Fitting the Random Forest model via scikit-learn\nforest.fit(X_train, y_train)\n\n# Making predictions\nforest_pred = forest.predict(X_test)\n\n# Setting up accuracy score\nforestaccuracy = accuracy_score(y_test, forest_pred)\nprint(\"Forest Accuracy \", {forestaccuracy})\n\n# Load the test data from test CSV file\ntest_data = pd.read_csv('/kaggle/input/mini-kaggle2-dataset/test.csv')\n\n# Drop the same columns from the test data\ntest_data = test_data.drop('id', axis=1)\n\n# Make predictions on the test data\npredictions = forest.predict(test_data)\n\n# Create a new DataFrame from predictions conducted\nnew_predictions_df = pd.DataFrame({'Predictions': predictions})\n\n# Reload the test.csv DataFrame to add back id column\ntest_data2 = pd.read_csv('/kaggle/input/mini-kaggle2-dataset/test.csv')\n\n# Add the id column from test_data2 to the new DataFrame\nnew_predictions_df.insert(0, 'id', test_data2['id'])\n\n# Save the predictions to a new CSV file\nnew_predictions_df.to_csv('prediction.csv', index=False)\n\n# Print new DataFrame\nprint(new_predictions_df)\n\n# While the logistic regression performed better in the training portion of the evaluation, \n# the results show that Random Forest fared better overall in terms of accuracy. Some possible \n# reasons for this could be the Random Forest classification's ability to handle non-linearity \n# more efficiently compared to Logistic Regression, which assumes a linear relationship between \n# the features. It can also handle outliers and overfitting more efficiently when compared to \n# Logistic Regression, which could also explain its better accuracy. ","metadata":{"execution":{"iopub.status.busy":"2024-03-26T11:18:12.889114Z","iopub.execute_input":"2024-03-26T11:18:12.889529Z","iopub.status.idle":"2024-03-26T11:18:13.049417Z","shell.execute_reply.started":"2024-03-26T11:18:12.889495Z","shell.execute_reply":"2024-03-26T11:18:13.048518Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Forest Accuracy  {0.9562043795620438}\n           id Predictions\n0      906564           B\n1       85715           M\n2      891670           B\n3      874217           M\n4      905680           B\n..        ...         ...\n109     87164           M\n110  84348301           B\n111    859471           B\n112    911150           B\n113  90944601           B\n\n[114 rows x 2 columns]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}}]}